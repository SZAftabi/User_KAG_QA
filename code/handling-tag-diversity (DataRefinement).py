# -*- coding: utf-8 -*-
"""Hnadling-Tag-Diversity (Libraries).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JAsqIxKRWMw2WAAYy2UQLkqqlnkiNmQn
"""

# ADD this code to the starting point of the whole code
data_path = "PATH/TO/CQADupStack/DATA"
MyData = pd.read_pickle(data_path)
tags_series = MyData['tags']
tags_lists = tags_series.str.split(',').apply(lambda tags: [t.strip() for t in tags])
posts = tags_lists.tolist()
tags = list(OrderedDict.fromkeys(tag for post in posts for tag in post))

#i.e., Train & Test data for fine-tuning Llama-2
data_path_LLama = f"PATH/TO/YOUR/DATA"
MyData_LLama = pd.read_pickle(data_path_LLama)
TG_Data = MyData_LLama[['body_Q1', 'tags_Q1']]
TG_Data = TG_Data.rename(columns={'body_Q1': 'text', 'tags_Q1': 'tags'})

tag_mapping = {}
for index, row in hierarchical_df.iterrows():
    tags = [row['Level 1'], row['Level 2'], row['Level 3']]
    tag_mapping[row['Tag']] = ', '.join(tags)

result_tags_list = []
oldtags_list = []
tags_with_duplicates_list = []
for tags_str in TG_Data['tags']:
    tags = tags_str.split(', ')
    processed_tags = [
        tag_mapping.get(tag, tag) if len(tag_mapping.get(tag, tag)) != 0
        else tag
        for tag in tags
    ]
    result_tags_list.append(', '.join(processed_tags))
    oldtags_list.append(', '.join(tags))
    tags_with_duplicates_list.append(', '.join(processed_tags))


result_dataframe = pd.DataFrame({
    'text': TG_Data['text'],
    'oldtags': oldtags_list,
    'newtags': result_tags_list,
    'tags_with_duplicates': tags_with_duplicates_list
})
tag_frequencies_list = [
    dict(Counter(tags.split(', ')))
    for tags in result_tags_list
]
result_dataframe['tag_frequencies'] = tag_frequencies_list
result_dataframe['newtags'] = result_dataframe.apply(
    lambda row: ', '.join(
        sorted(
            set(row['newtags'].split(', ')),
            key=lambda tag: (
                row['tag_frequencies'].get(tag, 0),
                -row['newtags'].split(', ').index(tag)
            ),
            reverse=True
        )
    ),
    axis=1
)

result_dataframe = result_dataframe[[
    'text',
    'oldtags',
    'newtags',
    'tags_with_duplicates',
    'tag_frequencies'
]]
TG_Data_After_HieClustering_file_name = f"PATH/TO/SAVE/DATA/FOR/LLAMA.pkl"
result_dataframe.to_pickle(TG_Data_After_HieClustering_file_name)